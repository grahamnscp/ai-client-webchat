# ai-client-webchat
Dev test sample webapp to front proxy messages to local open webui instance
  
Tested with openlit server running in docker - https://github.com/openlit/openlit  
Note that open telemetry libraries also register in this local deployment  

environment variables are set using direnv .envrc (not in repo)  

### TO-DO:
* Add dropdown for selecting model from available list in Ollama API
